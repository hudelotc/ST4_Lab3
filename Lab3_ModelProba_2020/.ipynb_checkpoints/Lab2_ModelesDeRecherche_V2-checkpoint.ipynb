{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QICsOhm7j_uP"
   },
   "source": [
    "# Recherche d'Information et traitement de données massives\n",
    "## Lab 2 : Modèles de Recherche\n",
    "\n",
    "L'objectif de cette séance est de mettre en oeuvre les différents modèles de recherche vus en cours. La première partie du Lab correspond à des exercices d'application de cours sur les différents modèles. La deuxième partie est la mise en oeuvre des différents modèles sur le corpus TIME.\n",
    "\n",
    "\n",
    "### Partie 1 : Exercices\n",
    "\n",
    "#### MODELE BOOLEEN\n",
    "\n",
    "Dans cet exercice, on considère une collection très petite constituée des documents ci-dessous :\n",
    "\n",
    "1. Doc1 = \"information retrieval and massive data processing\"\n",
    "2. Doc2 = \"introduction to information retrieval \"\n",
    "3. Doc3 = \"mining massive dataset\"\n",
    "4. Doc4 = \"modern information retrieval\"\n",
    "5. Doc5 = \"search engine information retrieval in practice\"\n",
    "6. Doc6 = \"information retrieval implementing and evaluating search engine\"\n",
    "\n",
    "**Exercice 1**\n",
    "\n",
    "Construire à la main la matrice terme-incidence de cette collection en considérant l'ensemble de mots vides suivants `Stop_words = [\"and\", \"to\", \"in\"]`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bia9wilfj_uT"
   },
   "source": [
    "**Exercice 2**\n",
    "\n",
    "Quels sont les réponses aux requêtes ci-dessous :\n",
    "\n",
    "1. Query 1 = \"information AND retrieval and NOT massive\"\n",
    "2. Query 2 = \"search and engine AND NOT practice \"\n",
    "3. Query 3 = \"(information OR search) AND retrieval\"\n",
    "\n",
    "\n",
    "**Exercice 3**\n",
    "\n",
    "Nous allons maintenant vérifier les réponses aux exercices 1 et 2 de manière expérimentale. On considère donc la collection comme représentée ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AqYfaWF-j_uV"
   },
   "outputs": [],
   "source": [
    "D1 = \"information retrieval and massive data processing\"\n",
    "D2 = \"introduction to information retrieval\"\n",
    "D3 = \"mining massive dataset\"\n",
    "D4 = \"modern information retrieval\"\n",
    "D5 = \"search engine information retrieval in practice\"\n",
    "D6 = \"information retrieval implementing and evaluating search engine\"\n",
    "\n",
    "Collection = {\"DOC1\": D1,\n",
    "            \"DOC2\": D2, \n",
    "            \"DOC3\": D3, \n",
    "            \"DOC4\": D4 ,\n",
    "            \"DOC5\": D5,\n",
    "             \"DOC6\" : D6}\n",
    "\n",
    "StopWords = [\"and\", \"to\",\"in\"]\n",
    "\n",
    "BooleanOperator = {'AND', 'OR', 'NOT'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eeiXwbpbj_uc",
    "outputId": "713e4a6b-bd6e-436e-fc71-9819dec23d46"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DOC1': 'information retrieval and massive data processing',\n",
       " 'DOC2': 'introduction to information retrieval',\n",
       " 'DOC3': 'mining massive dataset',\n",
       " 'DOC4': 'modern information retrieval',\n",
       " 'DOC5': 'search engine information retrieval in practice',\n",
       " 'DOC6': 'information retrieval implementing and evaluating search engine'}"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4_vjolhnj_uk"
   },
   "source": [
    "Ecrire une fonction permettant de filtrer la collection des stop words et qui renvoie la collection filtrée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WUcwd2vGTzXQ"
   },
   "outputs": [],
   "source": [
    "def remove_stop_word(collection):\n",
    "    filtered_collection ={}\n",
    "    # a completer\n",
    "    return filtered_collection\n",
    "\n",
    "\n",
    "\n",
    "Filtered_Collection = remove_stop_word(Collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FbBFLY2KTzXU"
   },
   "source": [
    "Ecrire une fonction permettant d'extraire le vocabulaire extrait de la collection (termes uniques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CqBp_4QoTzXX"
   },
   "outputs": [],
   "source": [
    "# a completer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AKABp1L8TzXb"
   },
   "source": [
    " Ecrire une fonction `term_document_incidence_matrix (Collection,Vocabulary)` qui construit et renvoie la matrice terme-incidence d'une collection donnée en paramètre.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3wWCjcOYTzXd"
   },
   "outputs": [],
   "source": [
    "def term_document_incidence_matrix (Collection,Vocabulary):\n",
    "    term_document_matrix = {}\n",
    "    # A completer\n",
    "    return term_document_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lf-lShP3TzXi"
   },
   "source": [
    "Appliquer cette fonction sur la collection des 6 documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lwsum-m9TzXk"
   },
   "outputs": [],
   "source": [
    "# a completer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PUnLAFzcTzXo"
   },
   "source": [
    "Ecrire une fonction `term_incidence_vector (term)` retournant le vector d'incidence d'un terme donné en paramètre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v9Gb71TlTzXu"
   },
   "outputs": [],
   "source": [
    "def term_incidence_vector(term):\n",
    "    # a completer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NvxAGBt1TzX0"
   },
   "source": [
    "La fonction donnée ci-dessous permet d'afficher un dictionnaire ligne par ligne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "du6lclgiTzX1"
   },
   "outputs": [],
   "source": [
    "def displayDict(D):\n",
    "    print(\"\\n\")\n",
    "    for i in D:\n",
    "        print (i , \" : \" ,D[i])\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-FEUrUUxTzX-"
   },
   "source": [
    "Appliquer le code ci-dessous pour vérifier que la matrince terme incidence construite correspond bien à celle que vous avez construit manuellement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hUl8hzA5TzX_"
   },
   "outputs": [],
   "source": [
    "# Affichage de la matrice terme incidence \n",
    "print(\"Term-Document incidence Matrix\\n\")\n",
    "displayDict(term_document_incidence_matrix (Collection,Vocabulary))\n",
    "print (\"Incidence Vector of information\", term_incidence_vector('information'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T2lJBBzrTzYC"
   },
   "source": [
    "Ecrire une fonction `query_processing(query)` qui prend en entrée une requête sous la forme d'une chaîne de caractères et qui renvoie la représentation d'une requête sous la forme d'une liste de termes et d'opérateurs booléens définis ici : `BooleanOperator = {'AND', 'OR', 'NOT'}`.\n",
    "Par exemple pour la requête `\"information AND retrieval and NOT massive\"` la fonction renverra la liste `[ \"information\", \"AND\", \"retrieval\", \"AND\", \"NOT\", \"massive\"]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dH4C0KlVTzYE"
   },
   "outputs": [],
   "source": [
    "def query_processing(query):\n",
    "    processed_query=[]\n",
    "    # a completer\n",
    "    return processed_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N-VqnoviTzYJ"
   },
   "source": [
    "On considère la fonction `boolean_operator_processing (BoolOperator,term1,term2)` permettant de calculer le résultat de `term1 BoolOperator term2`. Cette fonction utilise la fonction `zip` de python décrite [ici](https://docs.python.org/3.3/library/functions.html#zip).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oo48kxgkTzYK"
   },
   "outputs": [],
   "source": [
    "def boolean_operator_processing(BoolOperator,term1,term2):\n",
    "    result=[]\n",
    "    if BoolOperator == \"AND\":\n",
    "        for a , b in zip(term1,term2) :\n",
    "            if a==1 and b==1 :\n",
    "                result.append(1)\n",
    "            else :\n",
    "                result.append(0)\n",
    "    elif BoolOperator==\"OR\" :\n",
    "        for a,b in zip(term1,term2)  :\n",
    "            if a==0 and b==0 :\n",
    "                result.append(0)\n",
    "            else :\n",
    "                result.append(1)\n",
    "    elif BoolOperator == \"NOT\":\n",
    "        for b in term1 :\n",
    "            if b == 1 :\n",
    "                result.append(0)\n",
    "            else :\n",
    "                result.append(1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r3GM8-YmTzYP"
   },
   "source": [
    "Appliquer le code ci-dessous pour tester cette fonction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sipJGkZcTzYR",
    "outputId": "24ba5c3b-9560-4980-f465-8a02a6a84d25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1]\n",
      "[0, 1, 1, 1]\n",
      "[1, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "v1=[0,1,0,1]\n",
    "v2=[0,0,1,1]\n",
    "v3=[]\n",
    "print(boolean_operator_processing(\"AND\",v1,v2))\n",
    "print(boolean_operator_processing(\"OR\",v1,v2))\n",
    "print(boolean_operator_processing(\"NOT\",v1,v3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b5NdkwrnTzYX"
   },
   "source": [
    "Ecrire une fonction `query_processing (term_incidence_matrix, query)` permettant de traiter la requête `query` en utilisant la matrice `term_incidence_matrix` et donc en appliquant les opérations binaires sur les vecteurs d'incidence des différents termes de la requête. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xC91-VjiTzYa"
   },
   "outputs": [],
   "source": [
    "def query_processing (term_incidence_matrix, query):\n",
    "    # A completer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MCYkhlc7TzYf"
   },
   "source": [
    "Appliquer cette fonction aux 3 requêtes de l'exercice 2 et vérifier que le résultat est le même que celui calculé à la main."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YFWuVDfwTzYg"
   },
   "outputs": [],
   "source": [
    "# A completer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5ieTRPxrj_um"
   },
   "source": [
    "#### MODELE VECTORIEL\n",
    "**Exercice 4**\n",
    "\n",
    "Considérons une requête $q$ contenant les terme *OS, Jaguar* et trois documents de même taille $d_1$, $d_2$ et $d_3$ qui contiennent respectivement *Jaguar, Jaguar, Jungle, Jungle, Jungle*, et *Système d'exploitation, Jaguar, Mac, Système d'exploitation* et *Jaguar, Bentley, Mercedes, Jaguar, Jaguar*.  Dans la suite, nous utiliserons l'abréviation S.E. pour *Système d'exploitation* et nous supposerons que le vocabulaire associé est : \n",
    "\n",
    "$$\\mathcal{V} = \\{ bentley, jaguar, jungle, mac, mercedes, os, S.E.\\} $$\n",
    "\n",
    "1. Donner les vecteurs associés aux documents et à la requête. \n",
    "2. Dans le cas où on privilégie une représentation à base de $tf$, ordonner les documents par rapport à leur score (i.e. produit scalaire) avec la requête.\n",
    "\n",
    "\n",
    " *Jaguar* est un terme polysémique et on voit bien sur l'exemple précédent que si un terme polysémique d'une requête est répété plusieurs fois dans des documents traitant d'autres sujets que ce que l'on recherche, ces documents obtiendront un meilleur score que ceux traitant du sujet mais contenant moins d'occurrences du terme polysémique. Une solution est d'augmenter la couverture des termes du vocabulaire en prenant en compte, dans la représentation vectorielle des documents de la requête, les termes synonymes de ceux apparaissant dans les documents et la requête. Un moyen simple pour cela consiste à définir une matrice de similarité $W$ entre les termes et de projeter les documents et la requête sur cette matrice avant de calculer leurs scores. Pour notre exemple, considérons la matrice de similarité entre les termes suivante :\n",
    "\n",
    "$$\\begin{pmatrix}\n",
    "0.5 & 0.1 & 0 & 0 & 0.4 & 0 & 0 \\\\\n",
    "0.1 & 0.5 & 0.05 & 0.05 & 0.1 & 0.1 & 0.1 \\\\\n",
    "0 & 0.05 & 0.95 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0.05 & 0 & 0.8 & 0 & 0.05 &  0.1 \\\\\n",
    "0.4 & 0.1 & 0 & 0 & 0.5 & 0 & 0 \\\\\n",
    "0 & 0.1 & 0 & 0.05 & 0 & 0.55 & 0.3 \\\\\n",
    "0 & 0.1 & 0 & 0.1 & 0 & 0.3 & 0.5\n",
    "\\end{pmatrix}$$\n",
    "\n",
    "\n",
    "3. Quelles sont les nouvelles représentations des documents $d_1$, $d_2$ et $d_3$ ainsi que de la requête $q$ ? Calculer les nouveaux scores produits scalaires entre ces documents et $q$ et ordonner ces derniers par rapport à ces scores. Conclure.\n",
    "4. Si on suppose que les termes qui apparaissent dans les mêmes documents avec les mêmes fréquences sont sémantiquement similaires, donner un moyen simple de calculer la matrice de similarité entre termes, $W$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VALjVBNTj_uo"
   },
   "source": [
    "#### MODELE PROBABILISTE\n",
    "**Exercice 5 (à la maison)**\n",
    "\n",
    "On considère la fonction $h$ qui intervient dans le calcul du score OKAPI BM25 (cf. support de cours 2) : \n",
    "$$\\begin{align}\n",
    "h : \\mathbb{R}^+\n",
    " &\\rightarrow \\mathbb{R}\\\\\n",
    " x & \\mapsto \\ln \\frac{\\left(\\alpha \\lambda^xe^{-\\lambda} + \\left( 1 - \\alpha \\right) \\mu^x e^{-\\mu}\\right) \\left( \\beta e^{-\\lambda} + \\left( 1 - \\beta \\right) e^{- \\mu}  \\right)}{ \\left( \\beta \\lambda^x e^{-\\lambda} + \\left( 1 - \\beta \\right) \\mu^x e^{-\\mu} \\right) \\left( \\alpha e^{-\\lambda} + \\left( 1 - \\alpha\\right) e^{-\\mu} \\right)}\n",
    " \\end{align}$$\n",
    "\n",
    "où $\\alpha \\in ]0,1[$, $\\beta \\in ]0,1[$ et $\\mu < \\lambda$.\n",
    "1. Quelles sont les caractéristiques de la fonction $h$ (description) ? \n",
    "2. Quelle est la limite $\\lim_{x \\rightarrow + \\infty} \\ln h(x)$ ?\n",
    "\n",
    "\n",
    "\n",
    "**Exercice 6 (à la maison)**\n",
    "\n",
    "On considère une collection de documents $\\mathcal{C} = \\left\\{ d_1, \\cdots, d_i, \\cdots, d_N \\right\\}$ et un ensemble de requêtes $\\mathcal{Q} = \\left\\{ q_1, \\cdots, q_l, \\cdots, q_L \\right\\}$ données, où pour chaque couple $\\left( d_i,q_l \\right) \\in \\mathcal{C} \\times \\mathcal{Q}$ on dispose d'un jugement de pertinence binaire $R$. On suppose de plus que chaque document $d_i \\in \\mathcal{C}$ est représenté par un vecteur binaire de dimension $V$, $\\textbf{d}_i= \\left( t_{1,i}, \\cdots, t_{j,i}, \\cdots t_{V,i}\\right)$. Rappelons la probabilité $p_j := P\\left( t_{j,i} = 1 | R=1,q \\right)$ (resp. $s_j:= P\\left( t_{j,i} = 1 | R=0,q \\right)$) que le terme d'indice $j$ du vocabulaire apparaisse dans un document pertinent (resp. non pertinent) vis-à-vis de la requête $q$. \n",
    "\n",
    "1. Pour une requête fixe $q$, quelles sont les lois de probabilité suivies par le $j$ème terme du vocabulaire, si ce dernier apparaît dans un document $d_i$ pertinent ou non pertinent vis-à-vis de cette requête ? (Nous notons $t_{j,i}$ ce $j$ème terme).\n",
    "2. Soit $d_i$ (resp. $d_{i'}$) un document jugé pertinent (resp. non pertinent) pour une requête de $\\mathcal{Q}$. Montrer que $P \\left( t_{j,i}  |  R = 1, q\\right) = p_{j}^{t_{j}} (1-p_{j})^{(1- t_{j})}$, $\\forall t_{j,i} \\in \\textbf{d}_i$ et  $\\forall t_{j,i'} \\in \\textbf{d}_{i'}$  $P \\left( t_{j,i'}  |  R = 0, q\\right) =s_{j}^{t_{j, i'}} (1-s_{j})^{(1- t_{j, i'})}$.\n",
    "\n",
    "Nous noterons par la suite $P \\left( t_{j,i}  |  R = 1, q\\right) = P \\left( t_{j,i}  | p_j \\right)$ et $P \\left( t_{j,i}  |  R = 0, q\\right) = P \\left( t_{j,i}  | s_j \\right)$ où $p_j$ et $s_j$ jouent chacun le rôle de paramètre.\n",
    "\n",
    "3. On note $\\mathcal{R}$ (resp. $\\bar{\\mathcal{R}}$ ) le sous-ensemble des documents de $\\mathcal{C}$  jugés pertinents au moins une fois (respectivement jamais jugés pertinents), par rapport à une requête de $\\mathcal{Q}$ (i.e. $\\mathcal{C} = \\mathcal{R} \\cup \\bar{\\mathcal{R}}$). On suppose de plus que les termes apparaissant dans n'importe quel document de $\\mathcal{C}$ sont indépendants les uns des autres. Donner l'expression de $P(\\textbf{d}_i | \\textbf{p})$ pour $d_i \\in \\mathcal{R}$ et $\\textbf{p} = \\left( p_1, \\cdots, p_j, \\cdots p_V \\right)$ puis donner l'expression de $P(\\textbf{d}_{i'} | \\textbf{s})$ pour $\\textbf{d}_{i'} \\in \\bar{\\mathcal{R}}$ et $\\textbf{s} = \\left( s_1, \\cdots, s_j, \\cdots, s_V \\right)$.\n",
    "\n",
    "\n",
    "4. Il existe différentes méthodes statistiques pour estimer les paramètres $\\textbf{p} = \\left( p_1, \\cdots, p_j, \\cdots p_V \\right)$ et $\\textbf{s} = \\left( s_1, \\cdots, s_j, \\cdots, s_V \\right)$, parmi lesquelles la méthode du maximum de vraisemblance (MV) qui est la plus utilisée dans la littérature. Nous allons estimer les paramètres (vecteurs) $\\textbf{p}$ et $\\textbf{s}$ respectivement sur les sous ensembles $\\mathcal{R}$ et $\\bar{\\mathcal{R}}$. Pour une collection de documents $\\mathcal{X} = \\left\\{ d_1, \\cdots, d_{| \\mathcal{X} |} \\right\\}$ ($\\mathcal{X}$ étant $\\mathcal{R}$ ou $\\bar{\\mathcal{R}}$), la méthode du MV consiste à trouver l'ensemble des paramètres $\\bm{\\lambda^{MV}}$ ($\\textbf{p}^{MV}$ ou $\\textbf{s}^{MV}$) qui maximise la vraisemblance des données $P(\\mathcal{X} | \\bm{\\lambda} )$. Dans le cas où on suppose que les documents sont tous indépendamment distribués, donner l'expression de $P(\\mathcal{X} | \\bm{\\lambda} )$.\n",
    "\n",
    "\n",
    "5. Dire pourquoi l'estimateur du maximum de vraisemblance $\\bm{\\lambda^{MV}}$ peut s'obtenir grâce à l'équation : \n",
    "$$\\bm{\\lambda^{MV}} = argmax_{\\bm{\\lambda}} \\ln\\left( P(\\mathcal{X} | \\bm{\\lambda} ) \\right) $$\n",
    "Soit le tableau de contingence suivant, comptabilisant la présence et l'absence du terme d'indice $j$ du vocabulaire dans les sous-ensembles $\\mathcal{R}$ et $\\bar{\\mathcal{R}}$.\n",
    "\n",
    "<img src=\"./Figures/TabContingence.png\" width=\"500\" height=\"200\" />\n",
    "\n",
    "6. Montrer que, $\\forall j \\in \\left\\{1, \\cdots, V \\right\\}$, $p_j^{MV} = \\frac{r}{|\\mathcal{R}|}$, $s_j^{MV}=\\frac{df_{t_j} - r}{N- |\\mathcal{R}|}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-wuYzeBDj_up"
   },
   "source": [
    "\n",
    "### Partie 2  : Mise en oeuvre sur la collection TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ryYW_jd5j_uq"
   },
   "outputs": [],
   "source": [
    "Dans cette partie, il s'agit de mettre en oeuvre les différents modèles de recherche sur la collection TIME en utilisant la représentation de la collection sous la forme d'un index inversé et les différents algorithmes vus en cours.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QuDvf-IHTzYv"
   },
   "source": [
    "Charger l'index inversé de la collection TIME construit et sauvegardé sous la forme d'un fichier dans le LAB1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k2oK1DofTzYw"
   },
   "outputs": [],
   "source": [
    "# A completer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GnDXPl_iTzY2"
   },
   "source": [
    "#### Modèle booléen\n",
    "\n",
    "**Représentation des requêtes**\n",
    "\n",
    "Une des premières étapes pour la mise en oeuvre du modèle booléen est la représentation d'une requête. En effet, dans le modèle booléen, les requêtes sont des expressions booléennes pouvant être définies à l'aide des opérateurs logiques `OR`, `AND NOT` et `AND`. Nous avons vu dans le cours qu'il pouvait être intéressant de représenter les requêtes par leur forme normale conjonctive afin d'optimiser leur traitement. \n",
    "\n",
    "Quelle structure de données proposée vous \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cj-Q38MpTzY4"
   },
   "source": [
    "Dans la suite, on considérera deux cas:\n",
    "+ 1er cas : les requêtes sont fournies en langage naturel comme par exemple dans le fichier [TIME.QUE](./Data/Time/TIME.QUE) fournis avec la collection TIME et il faudra donc transformer cette\n",
    "**Requêtes en langage naturel**\n",
    "Votre premier travail ici consiste donc à écrire une fonction `def representation_query(query) ` qui prend en compte une requête en langage naturel et qui la transforme on considèra que l'espace correspond à l'opérateur `AND`. Par exemple, la requête `KENNEDY ADMINISTRATION PRESSURE` correspond à la requête `kennedy AND administration AND pressure`. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copie de Lab2_ModelesDeRecherche.ipynb",
   "provenance": [
    {
     "file_id": "1avE8cpAyYUmU7VH38cPC08_7EyXTyHS9",
     "timestamp": 1557845035598
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
