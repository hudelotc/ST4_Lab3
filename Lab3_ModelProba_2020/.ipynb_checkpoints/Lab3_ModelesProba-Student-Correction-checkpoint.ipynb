{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QICsOhm7j_uP"
   },
   "source": [
    "# Recherche d'Information et traitement de données massives\n",
    "## Lab 3 : Modèles de recherche Probabilistes\n",
    "\n",
    "L'objectif de cette séance est de mettre en oeuvre les différents modèles de recherche dits \"probabilistes\" vus en cours 3. La première partie du Lab correspond à des exercices d'application de cours. La deuxième partie est la mise en oeuvre des différents modèles sur le corpus TIME."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VSc9RaPWNzOF"
   },
   "source": [
    "\n",
    "## Partie 1 : Exercices\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-wuYzeBDj_up"
   },
   "source": [
    "\n",
    "## Partie 2  : Mise en oeuvre sur la collection TIME\n",
    "\n",
    "\n",
    "Dans cette partie, il s'agit de **mettre en oeuvre les différents modèles probabilistes sur la collection TIME** en utilisant : \n",
    " + la représentation de la collection sous la forme d'un index inversé et \n",
    " + des requêtes ayant subies les mêmes traitements que ceux appliqués aux documents lors de la phase d'indexation. \n",
    "\n",
    "En effet, il est nécessaire de garantir que l'espace de représentation de la requête et du document sont les mêmes. Les modèles probabilistes font partis de l'ensemble des modèles de recherche en RI. Durant le LAB2 vous avez mis en pratique les modèles dits booléens et vectoriels. Ces derniers modélisent la pertinence d'un document par rapport à une requête en considérant respectivement un degrès de pertinence binaire ou de similarité (score basé sur le produit vectoriel entre représentation du document et celle de la requête). \n",
    "\n",
    "Les modèles probabilistes quant à eux poussent un peu plus loin la finesse de la modélisation et le calcul de la pertinence. Le principe général des modèles probabilistes consiste à inférer, étant données d'une part la représentation d'un document et d'autre part la représentation d'une requête, la probabilité de pertinence du document sachant la requête. L'idée principale est que plus la probabilité de pertinence d'un document de la collection est élevée plus le document répond au besoin de l'utilisateur tel que formulé par sa requête. C'est ainsi que les probabilités sont utilisées pour l'ordonnancement des documents par ordre de pertinence. Nous allons mettre en oeuvre deux modèles probabilistes populaires : **MIB** et **BM25** en implémentant pour chacun leur fonction score d'ordonnancement, toutes deux vues en cours.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uAwS7TJ9NzQ3"
   },
   "source": [
    "**Préliminaires** \n",
    "Tout d'abord, nous allons charger l'index inversé de la collection TIME construit et sauvegardé sous la forme d'un fichier dans le LAB1. Les différents index sont disponibles [ici](./Index). Nous avons aussi mis dans le répertoire [Utils](./Utils) un ensemble de modules python permettant de charger les index. Ensuite, nous avons besoin d'avoir accès aux requêtes pré-processées comme cela a été fait durant le LAB2 par la construction de la fonction `pre_processed_query(query)`. Nous vous proposons de la ré-utiliser ainsi que les fonctions écrites dans le LAB1. Pour des raisons pratiques, nous vous fournissons ces fonctions dans le fichier [Lab12.py](./Utils/Lab12.py) du répertoire [Utils](./Utils). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 443,
     "status": "error",
     "timestamp": 1558305153208,
     "user": {
      "displayName": "Tami Myriam",
      "photoUrl": "",
      "userId": "04534705195482337784"
     },
     "user_tz": -120
    },
    "id": "8CBtPjMwNzQ3",
    "outputId": "5839ed4e-cc28-45a7-f7a8-ff73b724739a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423 articles ont été parsés\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['KENNEDY', 'ADMINISTRATION', 'PRESSURE', 'NGO', 'DINH', 'DIEM', 'STOP']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Utils.saveandload_pickle import *\n",
    "from Utils.Lab12 import *\n",
    "\n",
    "#chargement des index inverses (document et frequence)\n",
    "document_index = load_inverted_index_pickle('./Index/index_document.pickle')\n",
    "frequence_index = load_inverted_index_pickle('./Index/index_frequence.pickle')\n",
    "#print(document_index)\n",
    "\n",
    "#chargement de la collection \n",
    "collection_TIME = loadData(\"./Data/Time/TIME.ALL\")\n",
    "pre_processed_collection_TIME = collection_lemmatize(remove_stop_words(tokenize_Regexp_corpus(collection_TIME),\"./Data/Time/TIME.STP\"))\n",
    "\n",
    "#Exemple de requete pre-processee\n",
    "pre_processed_query(\"KENNEDY ADMINISTRATION PRESSURE ON NGO DINH DIEM TO STOP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S5PsGu_cNzQ9"
   },
   "source": [
    "## Modèle d'Indépendance Binaire (MIB)\n",
    "\n",
    "**Fonction d'ordonnancement probabiliste du MIB ($RSV^{MIB}$)**\n",
    "\n",
    "La formulation de la **fonction d'ordonnancement du Modèle d'Indépendance Binaire** est :\n",
    "\n",
    "$$Score\\_MIB(d,q)=\\sum_{j:t_{j}=r_{j}=1} log \\left( \\frac{p_{j} (1-s_{j})}{s_{j} (1-p_{j})} \\right)$$\n",
    "\n",
    "où,\n",
    " + $r_j=1 \\,(\\mbox{resp}. t_j=1)\\, \\mbox{signifie la présence du}\\; j \\, \\mbox{ème terme}\\, t_j\\, \\mbox{du vocabulaire}\\, (j \\in \\{1, \\ldots , V \\})\\, \\mbox{dans la requête}\\, q\\, (\\mbox{resp. dans le document}\\, d$) ;\n",
    " + $p_j = P(t_{j}=1|R)\\, \\mbox{la probabilité de pertinence du terme}\\, t_j$ ;\n",
    " + $s_j = P(t_{j}=1|NR)\\, \\mbox{la probabilité de non-pertinence du terme}\\, t_j$.\n",
    "\n",
    "\n",
    "Nous avons vu en cours comment théoriquement calculer les probabilités, $p_j\\, \\mbox{et} \\, s_j$ à l'aide d'une table de contingence des occurrences des documents dans la collection pour une requête donnée. Cependant pour pouvoir compléter cette table nous avons besoin d'avoir accès à des données annotées (données d'apprentissage). C'est à dire pour lesquelles nous connaisons le résultat de pertinence et où nous avons accès à l'information de pertinence. Ici ce n'est pas  notre cas. On va devoir donc envisager une alternative. Une solution proposée dans le cours est d'utiliser l'approximation suivante :\n",
    "$$s_j \\approx \\frac{df_{t_j}}{N}$$\n",
    "où, $N$ est le nombre de documents de la collection et $df_{t_j}$ le nombre de documents de la collection contenant le terme $t_j$.\n",
    "Quant à $p_j$ plusieurs possibilités d'approximation exitent : \n",
    " + considérer $p_j$ constante, par exemple : 0.5 si aucune information n'est disponnible [Croft and Harper] ;\n",
    " + considérer $p_j$ proportionnelle à la probabilité d'occurrence dans la collection ;\n",
    " + considérer $p_j$ proportionnelle au logarithme de la probabilité d'occurence dans la collection [GREIFF, Sigir 98]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5VPY4ZLtNzQ-"
   },
   "source": [
    "1- Ecrire une fonction `get_sj(term,index_frequence,nb_doc)` qui calcule l'approximation de $s_j$ pour un terme $t_j$. En entrée de la fonction vous pouvez utiliser le terme `term` et l'index de fréquence `index_frequence` précédement chargé ainsi que le nombre de documents de la collection `nb_doc`. Il est égal à 523 pour la collection TIME mais si vous le souhaitez, vous pouvez le récupérer via le dictionnaire de statistiques construit dans le LAB2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2KCzdQ-5NzRA",
    "outputId": "c201e667-df77-40b3-bace-e2e38b6fe3b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01338432122370937"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import *\n",
    "\n",
    "def get_sj(term,index_frequence,nb_doc):\n",
    "    return len(index_frequence[term].keys())/nb_doc\n",
    "               \n",
    "get_sj(\"NASSAU\",frequence_index,523)\n",
    "#test = len(frequence_index[\"NASSAU\"].keys())\n",
    "#print(test)\n",
    "#print(frequence_index[\"NASSAU\"].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5ejbq8vjNzRJ"
   },
   "source": [
    "2- Ecrire une fonction `score_MIB_1 (doc_ID, query, index_frequence, nb_doc)` qui calcule le score de pertinence du modèle MIB pour un document identifié dans l'`index_frequence` par son `doc_ID` et une requête `query`, tous donnés en entrée pour le cas où $p_j=0.5$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bqPGd9hKNzRK",
    "outputId": "4b9e1927-f85d-4d44-a29c-0fc89feb62a0"
   },
   "outputs": [],
   "source": [
    "def score_MIB_1 (doc_ID, query, index_frequence, nb_doc):\n",
    "    pj=0.5\n",
    "    cj_all= [] #liste vide de stockage\n",
    "    query_pre_processed = pre_processed_query(query)\n",
    "    #Boucle sur chaque term sous la condition que le terme soit a la fois present dans doc et requete\n",
    "    for term in query_pre_processed:\n",
    "        if doc_ID in index_frequence[term]:\n",
    "            sj = get_sj(term, index_frequence, nb_doc)\n",
    "            cj = log(pj*(1-sj)/sj*(1-pj))\n",
    "            cj_all.append(cj)\n",
    "    return sum(cj_all) #return la somme de la liste\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DZ2lArQMNzRY"
   },
   "source": [
    "3- Appliquer cette fonction pour le cas de la requête \"KENNEDY ADMINISTRATION PRESSURE ON NGO DINH DIEM TO STOP\" et un document au choix de la collection. N'hésitez pas à changer de document 2 ou 3 fois et à répéter le test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JWT3qDKfNzRZ",
    "outputId": "1e8fe3fb-352f-42b3-8e17-cbed0a0a4c34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9289758914014707\n"
     ]
    }
   ],
   "source": [
    "score_MIB_test=score_MIB_1('017',\"KENNEDY ADMINISTRATION PRESSURE ON NGO DINH DIEM TO STOP\",frequence_index,523)\n",
    "\n",
    "print(score_MIB_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4- **(question optionnelle)** Ecrire les fonctions `score_MIB_2 ()` et `score_MIB_3 ()` correspondant aux deux autres solutions de calcul de $p_j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "21qOyyiHNzRr"
   },
   "source": [
    "5- Ecrire une fonction `ranking_score_MIB_1 ()` qui calcule pour une requête donnée en entrée le `score_MIB_1` avec tous les documents \"pertinents\" de la collection et renvoit en sortie la liste des couples : document pertinent puis score, ordonnée par score de pertinence décroissant. \n",
    "\n",
    "N.B : un document est dit ici \"pertinent\" dans le sens où il contient au moins un terme de la requête. Cela n'a rien à voir avec la notion de pertinence du cours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('464', 7.610525952144638),\n",
       "             ('480', 7.261789520009904),\n",
       "             ('269', 6.7143604560997705),\n",
       "             ('363', 6.7143604560997705),\n",
       "             ('334', 6.681550060743168),\n",
       "             ('390', 6.298922483626336),\n",
       "             ('418', 6.298922483626336),\n",
       "             ('544', 6.298922483626336),\n",
       "             ('053', 5.369946592224867),\n",
       "             ('228', 5.369946592224867),\n",
       "             ('320', 5.369946592224867),\n",
       "             ('396', 5.369946592224867),\n",
       "             ('414', 5.369946592224867),\n",
       "             ('434', 5.369946592224867),\n",
       "             ('470', 5.369946592224867),\n",
       "             ('498', 5.369946592224867),\n",
       "             ('508', 5.369946592224867),\n",
       "             ('519', 5.369946592224867),\n",
       "             ('533', 5.369946592224867),\n",
       "             ('559', 5.369946592224867),\n",
       "             ('516', 4.513638340559659),\n",
       "             ('163', 4.1652326830614115),\n",
       "             ('071', 4.132422287704809),\n",
       "             ('227', 3.584993223794676),\n",
       "             ('243', 3.584993223794676),\n",
       "             ('341', 3.203446396303339),\n",
       "             ('043', 2.820818819186508),\n",
       "             ('183', 2.820818819186508),\n",
       "             ('196', 2.820818819186508),\n",
       "             ('253', 2.820818819186508),\n",
       "             ('317', 2.820818819186508),\n",
       "             ('492', 2.820818819186508),\n",
       "             ('040', 2.656017332393205),\n",
       "             ('459', 2.656017332393205),\n",
       "             ('204', 2.273389755276374),\n",
       "             ('221', 2.273389755276374),\n",
       "             ('236', 2.273389755276374),\n",
       "             ('062', 2.2405793599197725),\n",
       "             ('188', 2.2405793599197725),\n",
       "             ('048', 1.8918429277850375),\n",
       "             ('098', 1.8918429277850375),\n",
       "             ('106', 1.8918429277850375),\n",
       "             ('302', 1.8918429277850375),\n",
       "             ('331', 1.8918429277850375),\n",
       "             ('501', 1.8918429277850375),\n",
       "             ('537', 1.8918429277850375),\n",
       "             ('552', 1.8918429277850375),\n",
       "             ('518', 1.6928195213731514),\n",
       "             ('545', 1.6928195213731514),\n",
       "             ('024', 1.3444138638749035),\n",
       "             ('099', 1.3444138638749035),\n",
       "             ('176', 1.3444138638749035),\n",
       "             ('186', 1.3444138638749035),\n",
       "             ('193', 1.3444138638749035),\n",
       "             ('225', 1.3444138638749035),\n",
       "             ('256', 1.3444138638749035),\n",
       "             ('276', 1.3444138638749035),\n",
       "             ('308', 1.3444138638749035),\n",
       "             ('330', 1.3444138638749035),\n",
       "             ('346', 1.3444138638749035),\n",
       "             ('365', 1.3444138638749035),\n",
       "             ('369', 1.3444138638749035),\n",
       "             ('384', 1.3444138638749035),\n",
       "             ('386', 1.3444138638749035),\n",
       "             ('405', 1.3444138638749035),\n",
       "             ('431', 1.3444138638749035),\n",
       "             ('461', 1.3444138638749035),\n",
       "             ('529', 1.3444138638749035),\n",
       "             ('536', 1.3444138638749035),\n",
       "             ('543', 1.3444138638749035),\n",
       "             ('562', 1.3444138638749035),\n",
       "             ('019', 1.3116034685183016),\n",
       "             ('058', 1.3116034685183016),\n",
       "             ('092', 1.3116034685183016),\n",
       "             ('104', 1.3116034685183016),\n",
       "             ('138', 1.3116034685183016),\n",
       "             ('153', 1.3116034685183016),\n",
       "             ('154', 1.3116034685183016),\n",
       "             ('215', 1.3116034685183016),\n",
       "             ('223', 1.3116034685183016),\n",
       "             ('238', 1.3116034685183016),\n",
       "             ('247', 1.3116034685183016),\n",
       "             ('250', 1.3116034685183016),\n",
       "             ('299', 1.3116034685183016),\n",
       "             ('335', 1.3116034685183016),\n",
       "             ('337', 1.3116034685183016),\n",
       "             ('345', 1.3116034685183016),\n",
       "             ('426', 1.3116034685183016),\n",
       "             ('442', 1.3116034685183016),\n",
       "             ('443', 1.3116034685183016),\n",
       "             ('504', 1.3116034685183016),\n",
       "             ('524', 1.3116034685183016),\n",
       "             ('556', 1.3116034685183016),\n",
       "             ('558', 1.3116034685183016),\n",
       "             ('017', 0.9289758914014707),\n",
       "             ('021', 0.9289758914014707),\n",
       "             ('028', 0.9289758914014707),\n",
       "             ('029', 0.9289758914014707),\n",
       "             ('045', 0.9289758914014707),\n",
       "             ('057', 0.9289758914014707),\n",
       "             ('067', 0.9289758914014707),\n",
       "             ('070', 0.9289758914014707),\n",
       "             ('105', 0.9289758914014707),\n",
       "             ('126', 0.9289758914014707),\n",
       "             ('217', 0.9289758914014707),\n",
       "             ('230', 0.9289758914014707),\n",
       "             ('252', 0.9289758914014707),\n",
       "             ('260', 0.9289758914014707),\n",
       "             ('287', 0.9289758914014707),\n",
       "             ('293', 0.9289758914014707),\n",
       "             ('348', 0.9289758914014707),\n",
       "             ('351', 0.9289758914014707),\n",
       "             ('353', 0.9289758914014707),\n",
       "             ('367', 0.9289758914014707),\n",
       "             ('370', 0.9289758914014707),\n",
       "             ('380', 0.9289758914014707),\n",
       "             ('392', 0.9289758914014707),\n",
       "             ('460', 0.9289758914014707),\n",
       "             ('463', 0.9289758914014707),\n",
       "             ('472', 0.9289758914014707),\n",
       "             ('561', 0.9289758914014707)])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creation d'une fonction pour créer la liste des documents pertinents associés à une requête\n",
    "def create_relevant_doc_IDs (query, index_frequence):\n",
    "    query_pre_processed = pre_processed_query(query)\n",
    "    relevant_doc_IDs = set()\n",
    "    for term in query_pre_processed:\n",
    "        relevant_doc_IDs.update(index_frequence[term].keys())\n",
    "    return sorted(relevant_doc_IDs)\n",
    "\n",
    "#test = create_relevant_doc_IDs(\"KENNEDY ADMINISTRATION PRESSURE ON NGO DINH DIEM TO STOP\",frequence_index)\n",
    "#print(test) \n",
    "\n",
    "def ranking_score_MIB_1 (query, index_frequence, nb_doc):\n",
    "    query_pre_processed = pre_processed_query(query)\n",
    "    score = {}\n",
    "    relevant_doc_IDs=create_relevant_doc_IDs(query,index_frequence)\n",
    "    for doc_ID in relevant_doc_IDs:\n",
    "        score[doc_ID] = score_MIB_1(doc_ID, query, index_frequence, nb_doc)   \n",
    "    #Ordonner\n",
    "    ordered_scores = OrderedDict(sorted(score.items(), key=lambda t: t[1], reverse=True))\n",
    "    # score.items() convert to a list of (elem, cnt) pairs\n",
    "    #return\n",
    "    return ordered_scores\n",
    "\n",
    "ranking_score_MIB_1(\"KENNEDY ADMINISTRATION PRESSURE ON NGO DINH DIEM TO STOP\",frequence_index,523)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6- **(question optionnelle)** Faire de même pour les cas des fonctions `score_MIB_2 ()` et `score_MIB_3 ()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7- **(question optionnelle)** Ecrire une fonction globale pour le \"ranking\" de documents pertinents par score MIB avec un paramètre d'entrée permettant de choisir parmi les fonctions de score `score_MIB_1 ()`, `score_MIB_2 ()` et `score_MIB_3 ()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8- Quelle information présente dans l'index inversé n'est pas utilisée par la modélisation MIB ? Quelle modélisation permet d'utiliser cette information pertinente ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Réponse**: Le nombre d'occurrence des termes. Le modèle BM25 va permettre de pousser un peu plus loin la modélisation MIB par l'utilisation de cette information appelée aussi `tf`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle BM 25 (\"Best Match\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XffwW52CNzR1"
   },
   "source": [
    "Le modèle BM 25, aussi nommé OKAPI BM 25, est une référence dans le développement des systèmes de recherche. Il est fondé sur un \"principe d'indexation probabiliste\" dont l'idée sous-jacente est qu'un bon descripteur de document est un terme assez fréquent dans ce document mais qui est relativement rare dans la collection. Cette idée a pour notions de bases la division des documents en deux ensembles élites $E$ et non élites $\\bar{E}$ et aussi celles de probabilités de pertinence d'un terme $p_j$ et $s_j$. En effet, sous le modèle BM 25 nous allons réecrire la fonction de score du modèle MIB en y intégrant :\n",
    "   + la notion d'élitisme des termes ;\n",
    "   + l'hypothèse que la fréquence d'un mot dans un document ne dépend que de l'appartenance du document à l'ensemble élite.\n",
    "\n",
    "En particulier, cela signifie qu'on va considérer que,\n",
    "   $p_j = P(TF_{j}=tf_{t_j,d} |R )$\n",
    "et que, \n",
    "   $s_j = P(TF_{j}=tf_{t_j,d} |NR )$\n",
    "\n",
    "avec $tf_{t_j,d}$ le nombre d'occurrences du terme dans le document. Quand le terme est absent $tf_{t_j,d}=0$. Ainsi, quand le terme est présent, le modèle tiendra aussi compte de sa fréquence d'apparition contrairement au modèle de base MIB.\n",
    "\n",
    "**Fonction d'ordonnancement probabiliste du BM 25**\n",
    "\n",
    "La formulation, ou plus exactement son approximation, de la **fonction d'ordonnancement du Modèle BM 25** est :\n",
    "\n",
    "$Score\\_BM25(d,q) = \\sum_{j:t_j=r_j=1} \\frac{(k_1 + 1) \\times tf_{t_j,d}}{k_1 ((1-b) + b \\frac{L_d}{m} )+ tf_{t_j,d}} \\times \\frac{(k_3 + 1) \\times tf_{t_j,q}}{k_3 + tf_{t_j,q}} \\times \\log \\frac{N - df_{t_j} + 0.5}{df_{t_j} + 0.5}$\n",
    "\n",
    "où,\n",
    " + $r_j=1$ (resp. $t_j=1$) signifie la présence du $j$ème terme $t_j$ du vocabulaire ($j \\in \\{1, \\ldots , V \\}$) dans la requête $q$ (resp. dans le document $d$) ;\n",
    " + $p_j = P(TF_{j}=tf_{t_j,d} |R )$ la probabilité de pertinence du terme $t_j$ ;\n",
    " + $s_j = P(TF_{j}=tf_{t_j,d} |NR )$ la probabilité de non-pertinence du terme $t_j$ ;\n",
    " + $df_{t_j}$ est le nombre de documents de la collection contenant le terme $t_j$ ;\n",
    " + $L_d$ est la longueur du document $d$ ;\n",
    " + $ m = \\frac{1}{N} \\sum_{d \\in \\mathcal{C}} L_d$ est la moyenne des tailles des documents de la collection ;\n",
    " + $k_1$ est le paramètre contrôlant la prise en compte de la fréquence des termes, par défaut $k_1 = 1.2$ ;\n",
    " + $b$ est le paramètre contrôlant la prise en compte de la longueur, par défaut $b = 0.75$ ;\n",
    " + $k_3$ est le paramètre contrôlant la prise en compte de la fréquence $tf_{t_i,q}$, par défaut on fixe $k_3 = 1000$ ;\n",
    " + $tf_{t_j,q}$ est le nombre d'occurrences du terme $t_j$ dans la requête $q$.\n",
    "\n",
    "\n",
    "A ce stade du LAB, nous savons calculer $tf_{t_j,d}$, $tf_{t_j,q}$, $df_{t_j}$ et nous connaissons $N$. Pour les éléments $k_1$, $k_2$, $k_3$ et $b$ il nous est possible de les fixer aux valeurs par défauts. Il nous reste donc à construire une fonction calculant $tf_{t_j,q}$ puis à calculer $L_d$ et $m$. Nous aurons alors à disposition tous le nécessaire pour calculer la fonction score du modèle BM 25. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9- Ecrire une fonction `get_tf_q (term, query)` permettant de calculer le nombre d'occurrence dans une requête `query` d'un `term` donnés tous deux en entrée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "def get_tf_q (term, query):\n",
    "    query_pre_processed = pre_processed_query(query)\n",
    "    query_index_frequence={}\n",
    "    for term in query_pre_processed:\n",
    "        if term in query_index_frequence:\n",
    "            query_index_frequence[term] = query_index_frequence[term] + 1\n",
    "        else:\n",
    "            query_index_frequence[term] = 1       \n",
    "    return query_index_frequence[term]\n",
    "\n",
    "test = get_tf_q(\"NGO\", \"KENNEDY ADMINISTRATION PRESSURE ON NGO DINH DIEM TO STOP\")\n",
    "print(test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I970DuQCNzR3",
    "outputId": "747d26e1-bc37-483e-d97e-1acfa5c3ee98"
   },
   "source": [
    "10- Ecrire une fonction `create_dict_size_docs_collection(pre_processed_collection_TIME)` qui construit à partir de la collection pré-processée (chargée au début de ce Lab) un dictionnaire où les clées sont les identifiants des documents et les valeurs les longueurs $L_d$ des documents. Puis calculer la longueur moyenne `m` des tailles des documents de la collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "568.8416075650118\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_dict_size_docs_collection(pre_processed_collection_TIME):\n",
    "    size_docs = {}\n",
    "    for doc_ID in pre_processed_collection_TIME:\n",
    "        size_docs[doc_ID] = len(pre_processed_collection_TIME[doc_ID])\n",
    "    return size_docs\n",
    "#Dictionnaire : pour chaque doc_ID on a sa longueur L_d\n",
    "dict_size_docs = create_dict_size_docs_collection(pre_processed_collection_TIME)\n",
    "#print(dict_size_docs)\n",
    "\n",
    "#Calcul de la moyenne des longueurs de documents de la collection\n",
    "sizes_docs = np.fromiter(dict_size_docs.values(), dtype=float)#to directly create numpy arrays from the dictionary values \n",
    "m = np.mean(sizes_docs)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11- Ecrire une fonction `score_BM25 (doc_ID, query, index_frequence, nb_doc, dict_size_docs, m)` qui calcule le score de pertinence du modèle BM25 pour un document identifié dans l'`index_frequence` par son `doc_ID` et une requête `query`. En entrée, vous pouvez utiliser les éléments créés à la question précédentes : `m`et `dict_size_docs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5497494628268647\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def score_BM25 (doc_ID, query, index_frequence, nb_doc, dict_size_docs, m):\n",
    "    #valeurs par defaut\n",
    "    k1 = 1.2\n",
    "    k3 = 1000\n",
    "    b = 0.75\n",
    "    query_pre_processed = pre_processed_query(query)\n",
    "    score_j_all = []\n",
    "    #Boucle sur chaque term sous la condition que le terme soit a la fois present dans doc et requete\n",
    "    for term in query_pre_processed:\n",
    "        if doc_ID in index_frequence[term]:\n",
    "            tf_dj = get_tf(term, doc_ID, frequence_index)\n",
    "            tf_qj = get_tf_q(term, query)\n",
    "            L_d = dict_size_docs[doc_ID]\n",
    "            df = len(index_frequence[term].keys())\n",
    "            first_j = ((k1+1)*tf_dj)/(k1*((1-b)+b*L_d/m)+tf_dj)\n",
    "            second_j = ((k3+1)*tf_qj)/(k3+tf_qj)\n",
    "            third_j = log((nb_doc - df + 0.5)/(df + 0.5))\n",
    "            score_j_all.append(first_j*second_j*third_j)\n",
    "    return sum(score_j_all)\n",
    "\n",
    "\n",
    "score_BM25_test= score_BM25('017',\"KENNEDY ADMINISTRATION PRESSURE ON NGO DINH DIEM TO STOP\",frequence_index,523, dict_size_docs, m)\n",
    "\n",
    "print(score_BM25_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gTfJf1skNzR6"
   },
   "source": [
    "12- Ecrire une fonction `ranking_score_BM25 ()` qui calcule pour une requête donnée en entrée le `score_BM25` avec tous les documents \"pertinents\" de la collection et renvoit en sortie la liste des couples : document pertinent puis score, ordonnée par score de pertinence décroissant. \n",
    "\n",
    "N.B : un document est dit ici \"pertinent\" dans le sens où il contient au moins un terme de la requête. Cela n'a rien à voir avec la notion de pertinence du cours.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5C46c-8SNzR6",
    "outputId": "e6b46ab6-c106-4176-9916-13db7c5aca8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('464', 17.767475692080396),\n",
       "             ('544', 17.48714198930351),\n",
       "             ('390', 16.923057580337595),\n",
       "             ('508', 16.819066451132443),\n",
       "             ('498', 16.443196305842825),\n",
       "             ('320', 15.44506385560713),\n",
       "             ('334', 15.397777303825062),\n",
       "             ('363', 15.12125251685056),\n",
       "             ('480', 14.540766569892472),\n",
       "             ('396', 14.144275719857431),\n",
       "             ('414', 14.08066767572192),\n",
       "             ('559', 13.868939522131058),\n",
       "             ('434', 13.788863042706133),\n",
       "             ('418', 13.710249832976041),\n",
       "             ('228', 13.31905964537699),\n",
       "             ('533', 12.761181650968538),\n",
       "             ('269', 12.606834930038026),\n",
       "             ('470', 11.928420082970135),\n",
       "             ('053', 10.821636846516585),\n",
       "             ('519', 10.801513325638467),\n",
       "             ('227', 10.510300681885656),\n",
       "             ('516', 8.853844093123287),\n",
       "             ('183', 8.610878564047477),\n",
       "             ('492', 7.954134823085159),\n",
       "             ('317', 7.296009824526854),\n",
       "             ('196', 7.290701250937882),\n",
       "             ('243', 7.0894208146591025),\n",
       "             ('221', 6.999713672141483),\n",
       "             ('043', 6.897406238549573),\n",
       "             ('188', 6.380072144326292),\n",
       "             ('062', 6.1247554125414645),\n",
       "             ('341', 6.049217907807641),\n",
       "             ('040', 5.92768191169157),\n",
       "             ('236', 5.791884266552312),\n",
       "             ('253', 5.727107117427863),\n",
       "             ('518', 5.536540107639072),\n",
       "             ('459', 5.266929067831437),\n",
       "             ('154', 4.538122619326261),\n",
       "             ('019', 4.353380908402556),\n",
       "             ('331', 4.029283059023839),\n",
       "             ('071', 4.01799560260551),\n",
       "             ('351', 3.815148613880122),\n",
       "             ('561', 3.7837029164744824),\n",
       "             ('153', 3.7482063415592433),\n",
       "             ('256', 3.7260134053671647),\n",
       "             ('106', 3.6906768213387613),\n",
       "             ('045', 3.6647665802532496),\n",
       "             ('384', 3.6119874145191675),\n",
       "             ('529', 3.5913800676293275),\n",
       "             ('367', 3.5848619619281132),\n",
       "             ('163', 3.5741835373854487),\n",
       "             ('017', 3.5497494628268647),\n",
       "             ('524', 3.4980816684289344),\n",
       "             ('276', 3.4885474407361614),\n",
       "             ('238', 3.47266963834132),\n",
       "             ('193', 3.412891746100041),\n",
       "             ('260', 3.4074534411017714),\n",
       "             ('176', 3.388397163425642),\n",
       "             ('335', 3.3875598297434912),\n",
       "             ('461', 3.3823283566974647),\n",
       "             ('504', 3.3753044907643357),\n",
       "             ('302', 3.3665622145438068),\n",
       "             ('552', 3.3590624106623297),\n",
       "             ('099', 3.358268974793542),\n",
       "             ('092', 3.2977565443675934),\n",
       "             ('562', 3.256912194357265),\n",
       "             ('230', 3.250491563853535),\n",
       "             ('426', 3.196083775369211),\n",
       "             ('225', 3.1935727949120123),\n",
       "             ('501', 3.1796177609927905),\n",
       "             ('098', 3.1011442088539685),\n",
       "             ('250', 3.100492822465756),\n",
       "             ('537', 3.075840108667324),\n",
       "             ('070', 3.0142454747418346),\n",
       "             ('287', 3.0094552184169223),\n",
       "             ('536', 2.9561157313625577),\n",
       "             ('223', 2.946283301029265),\n",
       "             ('442', 2.891496762548084),\n",
       "             ('048', 2.8910530291931904),\n",
       "             ('308', 2.886090223833815),\n",
       "             ('293', 2.878914888899731),\n",
       "             ('186', 2.763606781897607),\n",
       "             ('558', 2.720746561534151),\n",
       "             ('299', 2.6991011750932934),\n",
       "             ('346', 2.696522247543516),\n",
       "             ('247', 2.6701338191304766),\n",
       "             ('443', 2.632464227957292),\n",
       "             ('058', 2.5479901450424056),\n",
       "             ('543', 2.5051476263524766),\n",
       "             ('330', 2.4886409815071917),\n",
       "             ('369', 2.473969890780276),\n",
       "             ('463', 2.4203436360612396),\n",
       "             ('024', 2.3804160203173965),\n",
       "             ('104', 2.297058628195944),\n",
       "             ('057', 2.2906508822787752),\n",
       "             ('345', 2.2636197119009167),\n",
       "             ('556', 2.2499724329186117),\n",
       "             ('405', 2.2406125177980405),\n",
       "             ('067', 2.175625602494258),\n",
       "             ('545', 2.158159341159347),\n",
       "             ('028', 2.130801928572444),\n",
       "             ('217', 2.130801928572444),\n",
       "             ('386', 2.117506088065804),\n",
       "             ('380', 2.0742805244928135),\n",
       "             ('021', 2.0729393891491528),\n",
       "             ('431', 2.058643517008539),\n",
       "             ('215', 2.0352406100468374),\n",
       "             ('252', 2.0206801966632666),\n",
       "             ('126', 1.9770682172532572),\n",
       "             ('029', 1.970991138773627),\n",
       "             ('348', 1.9352990048411614),\n",
       "             ('460', 1.9306374873998609),\n",
       "             ('353', 1.9179333423624014),\n",
       "             ('472', 1.887448020284494),\n",
       "             ('392', 1.8600724370635646),\n",
       "             ('204', 1.7608780347208022),\n",
       "             ('105', 1.7532687692243019),\n",
       "             ('138', 1.7376769724817398),\n",
       "             ('365', 1.5025544307589513),\n",
       "             ('337', 1.1685462395898623),\n",
       "             ('370', 0.6034891339359687)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ranking_score_BM25 (query, index_frequence, nb_doc):\n",
    "    query_pre_processed = pre_processed_query(query)\n",
    "    score = {}\n",
    "    relevant_doc_IDs=create_relevant_doc_IDs(query,index_frequence)\n",
    "    for doc_ID in relevant_doc_IDs:\n",
    "        score[doc_ID] = score_BM25(doc_ID, query, index_frequence, nb_doc, dict_size_docs, m)\n",
    "    #Ordonner\n",
    "    ordered_scores = OrderedDict(sorted(score.items(), key=lambda t: t[1], reverse=True))\n",
    "    # score.items() convert to a list of (elem, cnt) pairs\n",
    "    #return\n",
    "    return ordered_scores\n",
    "\n",
    "ranking_score_BM25(\"KENNEDY ADMINISTRATION PRESSURE ON NGO DINH DIEM TO STOP\",frequence_index,523)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DxsJxRGzNzSC"
   },
   "source": [
    "13- Comparer les deux ranking renvoyés par chacun des modèles de recherche probabilistes pour une même requête `\"KENNEDY ADMINISTRATION PRESSURE ON NGO DINH DIEM TO STOP\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14- Comparer les rankings renvoyés par tous les modèles de recherches vus durant les Labs (probabilistes et vectoriel) pour la même requête `\"KENNEDY ADMINISTRATION PRESSURE ON NGO DINH DIEM TO STOP\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YD9k8Si5NzS_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "S5PsGu_cNzQ9"
   ],
   "name": "Lab2_ModelesDeRecherche-Student-final-Correction-all.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
