{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QICsOhm7j_uP"
   },
   "source": [
    "# Recherche d'Information et traitement de données massives\n",
    "## Lab 2 : Modèles de Recherche\n",
    "\n",
    "L'objectif de cette séance est de mettre en oeuvre les différents modèles de recherche vus en cours. La première partie du Lab correspond à des exercices d'application de cours sur les différents modèles. La deuxième partie est la mise en oeuvre des différents modèles sur le corpus TIME."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Partie 1 : Exercices\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODELE BOOLEEN\n",
    "\n",
    "Dans cet exercice, on considère une collection très petite constituée des documents ci-dessous :\n",
    "\n",
    "1. Doc1 = \"information retrieval and massive data processing\"\n",
    "2. Doc2 = \"introduction to information retrieval \"\n",
    "3. Doc3 = \"mining massive dataset\"\n",
    "4. Doc4 = \"modern information retrieval\"\n",
    "5. Doc5 = \"search engine information retrieval in practice\"\n",
    "6. Doc6 = \"information retrieval implementing and evaluating search engine\"\n",
    "\n",
    "**Exercice 1**\n",
    "\n",
    "Construire à la main la matrice terme-incidence de cette collection en considérant l'ensemble de mots vides suivants `Stop_words = [\"and\", \"to\", \"in\"]`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bia9wilfj_uT"
   },
   "source": [
    "**Exercice 2**\n",
    "\n",
    "Quels sont les réponses aux requêtes ci-dessous :\n",
    "\n",
    "1. Query 1 = \"information AND retrieval AND NOT massive\"\n",
    "2. Query 2 = \"search AND engine AND NOT practice \"\n",
    "3. Query 3 = \"(information OR search) AND retrieval\"\n",
    "\n",
    "\n",
    "**Exercice 3 (OPTIONNEL)**\n",
    "\n",
    "Nous allons maintenant vérifier les réponses aux exercices 1 et 2 de manière expérimentale. On considère donc la collection comme représentée ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AqYfaWF-j_uV"
   },
   "outputs": [],
   "source": [
    "D1 = \"information retrieval and massive data processing\"\n",
    "D2 = \"introduction to information retrieval\"\n",
    "D3 = \"mining massive dataset\"\n",
    "D4 = \"modern information retrieval\"\n",
    "D5 = \"search engine information retrieval in practice\"\n",
    "D6 = \"information retrieval implementing and evaluating search engine\"\n",
    "\n",
    "Collection = {\"DOC1\": D1,\n",
    "            \"DOC2\": D2, \n",
    "            \"DOC3\": D3, \n",
    "            \"DOC4\": D4 ,\n",
    "            \"DOC5\": D5,\n",
    "             \"DOC6\" : D6}\n",
    "\n",
    "StopWords = [\"and\", \"to\",\"in\"]\n",
    "\n",
    "BooleanOperator = {'AND', 'OR', 'NOT'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eeiXwbpbj_uc",
    "outputId": "713e4a6b-bd6e-436e-fc71-9819dec23d46"
   },
   "outputs": [],
   "source": [
    "Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4_vjolhnj_uk"
   },
   "source": [
    "1- Ecrire une fonction permettant de filtrer la collection des stop words et qui renvoie la collection filtrée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Collection' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c2f1c176a769>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mFiltered_Collection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_stop_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCollection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Collection' is not defined"
     ]
    }
   ],
   "source": [
    "def remove_stop_word(collection):\n",
    "    filtered_collection ={}\n",
    "    # à completer\n",
    "    return filtered_collection\n",
    "\n",
    "\n",
    "\n",
    "Filtered_Collection = remove_stop_word(Collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- Ecrire une fonction permettant d'extraire le vocabulaire extrait de la collection (termes uniques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# à completer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 3- Ecrire une fonction `term_document_incidence_matrix (Collection,Vocabulary)` qui construit et renvoie la matrice terme-incidence d'une collection donnée en paramètre.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_document_incidence_matrix (Collection,Vocabulary):\n",
    "    term_document_matrix = {}\n",
    "    # A completer\n",
    "    return term_document_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4- Appliquer cette fonction sur la collection filtrée des 6 documents et créer la matrice d'incidence en la nommant `matrix`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# à completer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5- Ecrire une fonction `term_incidence_vector (term, matrix)` retournant le vecteur d'incidence d'un terme donné en paramètre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-2-071eb6e46b6a>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-071eb6e46b6a>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    # à completer\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def term_incidence_vector(term, matrix):\n",
    "    # à completer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction donnée ci-dessous permet d'afficher un dictionnaire ligne par ligne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayDict(D):\n",
    "    print(\"\\n\")\n",
    "    for i in D:\n",
    "        print (i , \" : \" ,D[i])\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appliquer le code ci-dessous pour vérifier que la matrice d'incidence construite correspond bien à celle que vous avez construit manuellement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage de la matrice terme incidence \n",
    "print(\"Term-Document incidence Matrix\\n\")\n",
    "displayDict(term_document_incidence_matrix (Collection,Vocabulary))\n",
    "print (\"Incidence Vector of information\", term_incidence_vector('information'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6- Ecrire une fonction `query_pre_processing(query)` qui prend en entrée une requête sous la forme d'une chaîne de caractères et qui renvoie la représentation d'une requête sous la forme d'une liste de termes et d'opérateurs booléens définis ici par : `BooleanOperator = {'AND', 'OR', 'NOT'}`.\n",
    "Par exemple pour la requête `\"information AND retrieval AND NOT massive\"` la fonction renverra la liste `[ \"information\", \"AND\", \"retrieval\", \"AND\", \"NOT\", \"massive\"]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_pre_processing(query):\n",
    "    processed_query=[]\n",
    "    # à completer\n",
    "    return processed_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On considère la fonction `boolean_operator_processing (BoolOperator,term1,term2)` permettant de calculer le résultat de `term1 BoolOperator term2`. Cette fonction utilise la fonction `zip` de python décrite [ici](https://docs.python.org/3.3/library/functions.html#zip).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boolean_operator_processing(BoolOperator,term1,term2):\n",
    "    result=[]\n",
    "    if BoolOperator == \"AND\":\n",
    "        for a , b in zip(term1,term2) :\n",
    "            if a==1 and b==1 :\n",
    "                result.append(1)\n",
    "            else :\n",
    "                result.append(0)\n",
    "    elif BoolOperator==\"OR\" :\n",
    "        for a,b in zip(term1,term2)  :\n",
    "            if a==0 and b==0 :\n",
    "                result.append(0)\n",
    "            else :\n",
    "                result.append(1)\n",
    "    elif BoolOperator == \"NOT\":\n",
    "        for b in term1 :\n",
    "            if b == 1 :\n",
    "                result.append(0)\n",
    "            else :\n",
    "                result.append(1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appliquer le code ci-dessous pour tester cette fonction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1]\n",
      "[0, 1, 1, 1]\n",
      "[1, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "v1=[0,1,0,1]\n",
    "v2=[0,0,1,1]\n",
    "v3=[] #Astuce pour l'opération NOT\n",
    "print(boolean_operator_processing(\"AND\",v1,v2))\n",
    "print(boolean_operator_processing(\"OR\",v1,v2))\n",
    "print(boolean_operator_processing(\"NOT\",v1,v3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7- Ecrire une fonction `query_processing (term_incidence_matrix, query, booleanOperator)` permettant de traiter la requête pré-processée `query` en utilisant la matrice `term_incidence_matrix` et donc en appliquant les opérations binaires sur les vecteurs d'incidence des différents termes de la requête. \n",
    "\n",
    "**Astuce : on supposera que la requête est donnée sous sa [forme normale conjonctive](https://fr.wikipedia.org/wiki/Forme_normale_conjonctive) en notation polonaise inversée pour faciliter son evaluation (c.f. Partie 2 du LAB).** Par exemple, la forme normale conjonctive en notation polonaise inversée de la requête \"information AND retrieval AND NOT massive\" devient \"information retrieval AND massive NOT AND\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_processing (term_incidence_matrix, query):\n",
    "    # A completer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8- Appliquer cette fonction aux 3 requêtes de l'exercice 2 et vérifier que le résultat est le même que celui calculé à la main."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A completer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5ieTRPxrj_um"
   },
   "source": [
    "### MODELE VECTORIEL\n",
    "**Exercice 4**\n",
    "\n",
    "Considérons une requête $q$ contenant les terme *os, Jaguar* et trois documents de même taille $d_1$, $d_2$ et $d_3$ qui contiennent respectivement :\n",
    " + *Jaguar, Jaguar, Jungle, Jungle, Jungle*\n",
    " + *Système d'exploitation, Jaguar, Mac, Système d'exploitation, Système d'exploitation*\n",
    " + *Jaguar, Bentley, Mercedes, Jaguar, Jaguar* \n",
    " \n",
    "plus précisément :\n",
    "\n",
    "`q = {os, Jaguar}`\n",
    "\n",
    "`d_1 = {Jaguar, Jaguar, Jungle, Jungle, Jungle}`\n",
    "\n",
    "`d_2 = {Système d'exploitation, Jaguar, Mac, Système d'exploitation, Système d'exploitation}`\n",
    "\n",
    "`d_3 = {Jaguar, Bentley, Mercedes, Jaguar, Jaguar}`\n",
    "\n",
    "Dans la suite, nous utiliserons l'abréviation S.E. pour *Système d'exploitation* et nous supposerons que le vocabulaire associé est : \n",
    "\n",
    "$$\\mathcal{V} = \\{ bentley, jaguar, jungle, mac, mercedes, os, S.E.\\} $$\n",
    "\n",
    "**1. Donner les vecteurs associés aux documents et à la requête.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Dans le cas où on privilégie une représentation à base de $tf$, ordonner les documents par rapport à leur score (i.e. produit scalaire) avec la requête.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Jaguar* est un terme polysémique et on voit bien sur l'exemple précédent que si un terme polysémique d'une requête est répété plusieurs fois dans des documents traitant d'autres sujets que ce que l'on recherche, ces documents obtiendront un meilleur score que ceux traitant du sujet mais contenant moins d'occurrences du terme polysémique. Une solution est d'augmenter la couverture des termes du vocabulaire en prenant en compte, dans la représentation vectorielle des documents de la requête, les termes synonymes de ceux apparaissant dans les documents et la requête. Un moyen simple pour cela consiste à définir une matrice de similarité $W$ entre les termes et de projeter les documents et la requête sur cette matrice avant de calculer leurs scores. Pour notre exemple, considérons la matrice de similarité entre les termes suivante :\n",
    "\n",
    "$$\\begin{pmatrix}\n",
    "0.5 & 0.1 & 0 & 0 & 0.4 & 0 & 0 \\\\\n",
    "0.1 & 0.5 & 0.05 & 0.05 & 0.1 & 0.1 & 0.1 \\\\\n",
    "0 & 0.05 & 0.95 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0.05 & 0 & 0.8 & 0 & 0.05 &  0.1 \\\\\n",
    "0.4 & 0.1 & 0 & 0 & 0.5 & 0 & 0 \\\\\n",
    "0 & 0.1 & 0 & 0.05 & 0 & 0.55 & 0.3 \\\\\n",
    "0 & 0.1 & 0 & 0.1 & 0 & 0.3 & 0.5\n",
    "\\end{pmatrix}$$\n",
    "\n",
    "\n",
    "**3. Quelles sont les nouvelles représentations des documents $d_1$, $d_2$ et $d_3$ ainsi que de la requête $q$ ? Calculer les nouveaux scores produits scalaires entre ces documents et $q$ et ordonner ces derniers par rapport à ces scores. Conclure.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Si on suppose que les termes qui apparaissent dans les mêmes documents avec les mêmes fréquences sont sémantiquement similaires, donner un moyen simple de calculer la matrice de similarité entre termes notée $W$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-wuYzeBDj_up"
   },
   "source": [
    "\n",
    "## Partie 2  : Mise en oeuvre sur la collection TIME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ryYW_jd5j_uq"
   },
   "source": [
    "Dans cette partie, il s'agit de mettre en oeuvre les différents modèles de recherche sur la collection TIME en utilisant la représentation de la collection sous la forme d'un index inversé et les différents algorithmes vus en cours.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Charger l'index inversé de la collection TIME construit et sauvegardé sous la forme d'un fichier dans le LAB1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A completer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modèle booléen\n",
    "\n",
    "**Représentation des requêtes**\n",
    "\n",
    "Une des premières étapes pour la mise en oeuvre du modèle booléen est la représentation d'une requête. En effet, dans le modèle booléen, les requêtes sont des expressions booléennes pouvant être définies à l'aide des opérateurs logiques `OR`, `NOT` et `AND` comme par exemple la requête ` U.S AND War OR France`.  Nous avons vu dans le cours qu'il pouvait être intéressant de représenter les requêtes par leur [forme normale conjonctive](https://fr.wikipedia.org/wiki/Forme_normale_conjonctive) (conjonction de disjonctions) afin d'optimiser leur traitement à l'aide de l'index inversé. Dans la suite, nous supposerons donc que les requêtes sont exprimées souc cette forme. \n",
    "\n",
    "2- **Quelle structure de données informatique proposez-vous pour representer une requête sous forme normale conjonctive et faciliter son traitement ?** Puis, à partir de cette représentation, quelle stratégie mettre en place pour évaluer l'expression booléenne associée ?\n",
    "\n",
    "Indice :\n",
    "\n",
    "\n",
    "<img src=\"./Figures/booleantree.png\" width=\"500\" height=\"500\" />\n",
    "\n",
    "\n",
    "Une manière de faire pourrait être de récupérer les littéraux `U.S`et `France `et de leur appliquer l'opérateur `OR` puis de récupérer le littéral `War`de lui appliquer `NOT` et enfin d'appliquer l'opérateur `AND` aux deux résultats des évaluations précédentes. Si on écrit la formule selon cette stratégie, on obtient :\n",
    "` U.S France OR War NOT AND`. \n",
    "Cela correspond à la notation post-fixe de la formule. Cette notation, aussi connue sous le nom de [notation polonaise inversée](https://fr.wikipedia.org/wiki/Notation_polonaise_inverse) (en hommage à son créateur Jan Łukasiewicz grand logicien et philosophe polonais) est très pratique pour l'évaluation de la formule. Elle permet aussi de ne pas utiliser de parenthèses sans ambiguité.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer une expression en sa représentation sous forme d'arbre ou en sa notation post-fixe est un beau problème d'algorithmique et de programmation et vous pourrez y reflechir à la maison. Dans le Lab, pour nous éviter de passer trop de temps sur cette question, nous utiliserons la bibliothèque [`tt`](http://tt.brianwel.ch/en/latest/index.html) qui permet de travailler avec des expressions en logique booléenne sous python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installer la bibliothéque en executant la commande ci-dessous.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ttable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le code ci-dessous vous permet de transformer une requête exprimée sous la forme d'une chaîne de caractères en une formule booléeen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tt import BooleanExpression\n",
    "\n",
    "b = BooleanExpression('(War or France) and (not C)')\n",
    "print(b)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'instruction ci-dessous permet de récupérer l'arbre représentant la formule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.tree\n",
    "print(b.tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est aussi possible de récupérer l'ensemble des tokens avec l'instruction ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " b.tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De même, il est possible de récupérer l'ensemble des tokens dans l'ordre post-fixe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.postfix_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la suite, on considérera donc deux cas:\n",
    "\n",
    "+ 1er cas : les requêtes sont données en langage naturel (comme par exemple dans le fichier [TIME.QUE](./Data/Time/TIME.QUE)), fournies avec la collection TIME et il faudra donc transformer cette requête en expression logique. En particulier, on considèrera que l'espace correspond à l'opérateur `AND`. Par exemple, la requête `KENNEDY ADMINISTRATION PRESSURE` correspond à la requête `kennedy AND administration AND pressure`. \n",
    "\n",
    "3- Ecrire une fonction `def transformation_query_to_boolean(query)` qui permet de transformer une requête en langage naturel sous sa forme logique.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformation_query_to_boolean(query):\n",
    "    \n",
    "    # A completer\n",
    "    return boolean_query\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " + 2ème cas : les requêtes sont fournies comme une expression logique (par exemple `'(War or France) and (not C)'`) et il s'agit de la transformer sous une forme post-fixe pour son evaluation.\n",
    "\n",
    "4- En utilisant la bibliothèque `tt` comme montré précedemment, ecrire une fonction permettant de transformer une requête en son ensemble de tokens ordonnés par ordre post-fixe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A completer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Traitement des requêtes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il s'agit ici d'écrire une fonction `processing_boolean_query_with_inverted_index(booleanOperator,query, inverted_index)` qui permet de renvoyer la liste de documents pertinents pour la requête `query`. `booleanOperator`est l'ensemble des opérateurs booléens considérés et `inverted_index` est l'index inversé de la collection considérée.\n",
    "\n",
    "Quelques indications pour vous aider :\n",
    " + L'utilisation d'une structure de données [Pile](https://docs.python.org/3/tutorial/datastructures.html#using-lists-as-stacks) et de la notation polonaise inversée peut être utile pour l'évaluation de la requête complète.\n",
    " + Revoir le cours 1 sur le modèle booléen pour l'utilisation de l'index inversé dans ce cas.\n",
    " \n",
    "**On suppose que les listes de postings de l'index inversé sont triées par doc_id croissant**\n",
    "\n",
    "5- Pour faciliter l'écriture de cette fonction, nous allons d'abord écrire les fonctions :\n",
    "+ `def merge_and_postings_list(posting_term1,posting_term2)` qui applique l'opérateur AND à deux postings listes : intersection de posting liste (c.f. cours) ;\n",
    "+ `def merge_or_postings_list(posting_term1,posting_term2)` qui applique l'opérateur OR à deux postings listes : union de posting liste (c.f. cours) ;\n",
    "+ `def merge_and_not_postings_list(posting_term1,posting_term2)`qui calcule posting_term1 AND NOT posting_term2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'document_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e084b4e114a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Postings du terme {} : {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NASSAU'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdocument_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NASSAU'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Postings du terme {} : {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'FRANCE'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdocument_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'FRANCE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test du AND\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'document_index' is not defined"
     ]
    }
   ],
   "source": [
    "def merge_and_postings_list(posting_term1,posting_term2):\n",
    "    result=[]\n",
    "    # A completer\n",
    "    return result\n",
    "\n",
    "# Test \n",
    "print(\"Postings du terme {} : {}\".format('NASSAU',document_index['NASSAU']))\n",
    "print(\"Postings du terme {} : {}\".format('FRANCE',document_index['FRANCE']))\n",
    "print(\"Test du AND\")\n",
    "res = merge_and_postings_list(document_index[\"NASSAU\"], document_index[\"FRANCE\"])\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_or_postings_list(posting_term1,posting_term2):\n",
    "    result=[]\n",
    "    # A completer\n",
    "    return result\n",
    "\n",
    "\n",
    "# Test \n",
    "print(\"Postings du terme {} : {}\".format('NASSAU',document_index['NASSAU']))\n",
    "print(\"Postings du terme {} : {}\".format('FRANCE',document_index['FRANCE']))\n",
    "print(\"Test du OR\")\n",
    "res = merge_or_postings_list(document_index[\"NASSAU\"], document_index[\"FRANCE\"])\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_and_not_postings_list(posting_term1,posting_term2):\n",
    "    result=[]\n",
    "    # A completer\n",
    "    return result\n",
    "\n",
    "\n",
    "# Test \n",
    "print(\"Postings du terme {} : {}\".format('NASSAU',document_index['NASSAU']))\n",
    "print(\"Postings du terme {} : {}\".format('FRANCE',document_index['FRANCE']))\n",
    "print(\"Test du AND_NOT\")\n",
    "res = merge_and_not_postings_list(document_index[\"NASSAU\"], document_index[\"FRANCE\"])\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6- En utilisant les fonctions implémentées dans la question précédente, écrire la fonction `boolean_operator_processing_with_inverted_index(BoolOperator,posting_term1,posting_term2)` qui applique l'opérateur `BoolOperator` parmi (AND, OR et AND NOT) à deux posting listes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boolean_operator_processing_with_inverted_index(BoolOperator,posting_term1,posting_term2):\n",
    "    result=[]\n",
    "    # A completer\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7- Ecrire la fonction `def processing_boolean_query_with_inverted_index(booleanOperator,query, inverted_index)` qui permet de renvoyer la liste de documents pertinents pour la requête `query`. `booleanOperator`est l'ensemble des opérateurs booléens considérés et `inverted_index` est l'index inversé de la collection considérée.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_boolean_query_with_inverted_index(booleanOperator,query, inverted_index):\n",
    "    # A completer\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modèle vectoriel\n",
    "\n",
    "**Représentation des requêtes et des documents**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le modèle vectoriel, les requêtes et les documents ont le même type de représentation, un vecteur pondéré dans l'espace des termes d'indexation. Il est donc nécessaire de faire subir à votre requête, souvent exprimée en langage naturel, les mêmes traitements que ceux appliqués aux documents lors de la phase d'indexation  soit :\n",
    "+ L'étape de segmentation ;\n",
    "+ L'étape de filtrage ;\n",
    "+ L'étape de normalisation.\n",
    "\n",
    "Cela permettra notamment de garantir que l'espace de représentation de la requête et du document sont les mêmes.\n",
    "\n",
    "8- Ecrire une fonction `pre_processed_query(query)`qui prend en entrée une requête sous la forme d'une chaîne de caractères et qui renvoie la requête sous la forme d'une liste de termes filtrés et normalisés. On pourra pour cela ré-utiliser les fonctions écrites dans le Lab 1 et fournies dans le fichier [Lab1.py](./Utils/Lab1.py) du répertoire [Utils](./Utils).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Utils.Lab1 import *\n",
    "\n",
    "def pre_processed_query(query):\n",
    "    # A completer\n",
    "    return []\n",
    "\n",
    "    \n",
    "# Test\n",
    "pre_processed_query(\"KENNEDY ADMINISTRATION PRESSURE ON NGO DINH DIEM TO STOP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un choix doit cependant être fait sur la manière de pondérer les différents termes de la requête et des documents lors de la construction de leurs représentations. En particulier, différents schémas de pondération sont possibles.\n",
    "Il peut être intéressant de pouvoir comparer ces différents types de pondération ainsi, dans la suite nous nous intéresserons aux schémas de pondérations suivants :\n",
    "+ **Pondération binaire** comme dans le modèle booléen ;\n",
    "+ **Pondération `tf`** avec  $w_{id} = tf_{t_i,d}$ où $d$ peut être un document ou une requête ;\n",
    "+ **Pondération `tf-idf`** avec donc $w_{id} = tf_{t_i,d} \\times idf_{t_i}$ où $idf_{t_i} = \\log{\\frac{N}{df_{t_i}}}$ et $N$ étant le nombre de documents dans la collection ;\n",
    "+ **Pondération fréquentielle normalisée** qui consiste à normaliser les fréquences des termes apparaissant dans un document $d$ par la fréquence maximale dans le document $tf_{max_d} = \\max_{t \\in d} tf_{t,d}$ soit pour le terme $p_{tf_{t_i,d}}$ correspondant à la fréquence dans la collection la formule :\n",
    "$ p_{tf_{t_i,d}} = 0.5 + 0.5 \\times \\frac{tf_{t_i,d}}{tf_{max_d}}$ ;\n",
    "+ **Pondération logarithmique des termes** avec $p_{tf_{t_i,d}} = 1 + \\log{tf_{t_i,d}}$ si $tf_{t_i,d} > 0$ et $0$ sinon ;\n",
    "+ **Pondération logarithmique des termes normalisée** qui consiste à normaliser la caractéristique logarithmique précédente par une quantité dépendant de la moyenne $moy_{tf_d} = \\sum_{i=1}^{V}\\frac{tf_{t_i,d}}{|d|}$ ($|d|$ est le nombre de termes uniques du document $d$) des caractéristiques fréquentielles d'un document $d$ soit $ p_{tf_{t_i,d}} = \\frac{1 + \\log{tf_{t_i,d}}}{1 + \\log{moy_{tf_d}}}$ ;\n",
    "+ Et bien entendu, pour chacune de ces différentes pondérations fréquentielles des termes, il est possible de multiplier ou non par le poids du terme dans le collection $p_{df_{t_i}}$ qui peut être soit $idf_{t_i}$ soit une version normalisée $ max(0, \\log{\\frac{N -df_{t_i}}{df_{t_i}}})$.\n",
    "\n",
    "Ces schémas de pondération peuvent être appliqués au document et à la requête. Votre premier travail consiste donc à écrire les fonctions permettant de calculer à partir de l'index inversé et d'informations statistiques additionnelles sur la collection ces différents schémas de pondération."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9- Ecrire une fonction `get_tf (term,doc_ID, index_frequence)` qui permet de récupérer la fréquence d'un terme dans un document à partir d'un index de fréquence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils.saveandload_pickle import *\n",
    "\n",
    "# Chargement de l'index de frequence \n",
    "frequence_index = load_inverted_index_pickle('./Index/index_frequence.pickle')\n",
    "\n",
    "def get_tf(term,doc_ID,index_frequence):\n",
    "    # A completer\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10- Ecrire une fonction `get_tf_logarithmique (term,doc_ID, index_frequence)` qui permet de calculer la pondération logarithmique d'un terme. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_logarithmique (term,doc_ID, index_frequence):\n",
    "    # A completer\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour les autres schémas de pondération, il est nécessaire d'avoir au préalable calculé et stocké plusieurs informations statistiques sur la collection comme le nombre total de documents et pour chaque document, la fréquence maximale dans le document, le nombre de termes uniques dans le document ou encore la moyenne des fréquences dans un document. \n",
    "\n",
    "11- Ecrire une fonction `get_stats_document(document)` qui pour un document donné sous la forme d'une liste de tokens renvoie un dictionnaire avec les informations statistiques mentionnées ci-dessus (clés : \"freq_max\", \"unique_terms\", \"freq_moy\"). On pourra utiliser la collection `Counter` du module `collections` de la bibliothèque standard de python comme dans le LAB1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_stats_document(document):\n",
    "    stats={}\n",
    "    # A completer\n",
    "    return stats\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12- Ecrire une fonction `get_stats_collection(collection)` qui permet de calculer des informations statistiques sur la collection comme le nombre de documents et pour chaque document de la collection, les informations statistiques précédentes.\n",
    "La fonction retournera un dictionnaire avec les clés \"nb_docs\" et les doc_ID des documents de la collection. On supposera que la collection passée en paramètre est une collection segmentée et pré-traitée (filtrage et normalisation).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats_collection(collection):\n",
    "    stats={}\n",
    "    # A completer\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13- Appliquer cette fonction à la collection TIME. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423 articles ont été parsés\n"
     ]
    }
   ],
   "source": [
    "from Utils.Lab1 import *\n",
    "\n",
    "collection_TIME = loadData(\"./Data/Time/TIME.ALL\")\n",
    "\n",
    "pre_processed_collection_TIME = collection_lemmatize(remove_stop_words(tokenize_Regexp_corpus(collection_TIME),\"./Data/Time/TIME.STP\"))\n",
    "\n",
    "# A completer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14- Ecrire une fonction `get_tf_normalise(term,doc_ID, index_frequence,stats_collection)` qui calcule la pondération fréquentielle du terme `term` pour le document d'identifiant `doc_ID` à partir de l'index de fréquence `index_frequence` et d'informations statistiques sur la collection stockée dans le dictionnaire `stats_collection` construit à l'étape précédente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_normalise(term,doc_ID, index_frequence,stats_collection):\n",
    "        # A completer\n",
    "        return \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15- Ecrire une fonction `get_tf_logarithme_normalise(term,doc_ID, index_frequence,stats_collection)` qui calcule la pondération fréquentielle logarithmique normalisée du terme `term` pour le document d'identifiant `doc_ID` à partir de l'index de fréquence `index_frequence` et d'informations statistiques sur la collection stockées dans le dictionnaire `stats_collection` construit à l'étape précédente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_logarithme_normalise(term,doc_ID, index_frequence,stats_collection):\n",
    "        # A completer\n",
    "        return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16- Ecrire une fonction `get_idf (term ,index_frequence, nb_doc)` qui permet de calculer le logarithme de l'inverse normalisée de la fréquence documentaire $df_t$ d'un terme. `nb_doc`est le nombre de documents dans la collection. Il est égal à 523 pour la collection TIME ou vous pouvez le récupérer via le dictionnaire de statistiques construit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import *\n",
    "\n",
    "def get_idf(term,index_frequence,nb_doc):\n",
    "    # A completer\n",
    "    return \n",
    "               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Traitement des requêtes**\n",
    "\n",
    "17- Ecrire une fonction `processing_vectorial_query(query, inverted_index,stats_collection, weighting_scheme_document,weighting_scheme_query)` qui permet de renvoyer la liste de documents pertinents, ordonnés par pertinence, pour la requête `query` à partir de l'index de fréquence `inverted_index`. Les paramètres `weighting_scheme_document` et `weighting_scheme_query` permettent de définir le type de pondération choisie pour le document et pour la requête. On considérera les types suivants :\n",
    " + 'binary' : schema de pondération binaire.\n",
    " + 'frequency' : schema de pondération fréquentiel simple (`tf` seul).\n",
    " + 'tf_idf_normalize' : schema de pondération `tf_idf` avec la pondération fréquentielle normalisée pour le terme correspondant à la fréquence du terme dans le document.\n",
    " + 'tf_idf_logarithmic' : schema de pondération `tf_idf` avec la pondération fréquentielle logarithmique pour le terme correspondant à la fréquence du terme dans le document.\n",
    " + 'tf_idf_logarithmic_normalize' : schema de pondération `tf_idf` avec la pondération fréquentielle logarithmique normalisée pour le terme correspondant à la fréquence du terme dans le document.\n",
    "\n",
    "\n",
    "Vous pourrez pour cela vous appuyer sur l'algorithme décrit dans le support du cours 1 (version longue), slide 136. On ne considérera pour la requête que les schémas de pondération ('binary','frequency') et on prendra comme mesure de similarité le produit scalaire. On ne considérera donc pas de facteur de normalisation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_vectorial_query(query, inverted_index, stats_collection, weighting_scheme_document,weighting_scheme_query):\n",
    "    ordered_relevant_docs = {}\n",
    "    # a completer\n",
    "    return ordered_relevant_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18- Tester votre modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A compléter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Lab2_ModelesDeRecherche.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
